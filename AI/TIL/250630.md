## 목차
- [CNN](#cnn)
  - [이미지 분류](#이미지-분류)
    - [이미지 분류란](#이미지-분류란)
    - [CNN  Model](#cnn--model)
  - [CNN 구성요소](#cnn-구성요소)
  - [이미지 데이터 학습과정](#이미지-데이터-학습과정)
    - [Image Load](#image-load)
    - [Image Data Generator 클래스](#image-data-generator-클래스)
    - [데이터 증강](#데이터-증강)
  - [CNN 모델의 구성](#cnn-모델의-구성)
    - [초반](#초반)
    - [후반](#후반)
    - [합성곱 계산](#합성곱-계산)
    - [Filter](#filter)
    - [Feature map](#feature-map)
    - [stride](#stride)
    - [Padding](#padding)
    - [Activation](#activation)
    - [Pooling Layer](#pooling-layer)
      - [Max Pooling](#max-pooling)
      - [Average Pooling](#average-pooling)
      - [GloabalAveragePooling](#gloabalaveragepooling)
    - [Fully Connected Layer](#fully-connected-layer)
  - [Transfer Learning](#transfer-learning)
    - [전이 학습 방법](#전이-학습-방법)

# CNN
> Convolution Neural Network

## 이미지 분류

### 이미지 분류란
- **컴퓨터가** 사람처럼 시작적으로 사물을 인식하도 분류하는 작업
  - Computer Vision
- CNN 모델이 필요한 이유
  - 기존 신경망 모델에 비해 더 정교한 분석 가능
- 기본 구성요소 
  - 합성곱(Convolution)
  - HW 설계의 핵심

### CNN  Model
- Alexnet
  - 초기의 CNN 모델
- ResNet
  - 이때부터 사람보다 나은 능력을 보여줌
- SENet

> 전이 학습
> > 사전 학습된 모델의 가중치를 재사용하여 적은 데이터로 학습 가능

## CNN 구성요소
- Convolution Layer
  - 특징 추출
- Pooling Layer
  - 공간 정보를 요약하여 특징 강화
- Full-Connected Layer
  - 최종 결과값 계산

## 이미지 데이터 학습과정

<img src="./img_250630/Screenshot from 2025-06-30 09-22-48.png"><br>

### Image Load
- 전체 데이터가 작은 경우
  - 빠른 학습 가능(병렬 HW 이용)
  - 메모리가 충분해야함
- 전체 데이터가 큰 경우
  - batch size 단위로 이미지를 나눠 불러옴
  - 이미지 용량이 클 때 유용
  - 효율적 학습 가능

### Image Data Generator 클래스
- 기능
  - 원본 이미지를 불러옴
  - 크기 조정, 색상 변화, 회전 등 데이터 증강도 같이 처리 가능
  - 단순 불러오기의 경우
    - rescale=1/255.만 수행

- flow_from_directory
  - 디렉토리에서 데이터를 불러오는 함수
- flow_from_dataframe
  - 이미지 파일 경로와 이미지 레이블이 DataFrame 파일에 정리된 경우 사용 가능

### 데이터 증강

<img src="./img_250630/Screenshot from 2025-06-30 09-28-21.png"><br>

## CNN 모델의 구성

[구성 사진]
<img src="./img_250630/Screenshot from 2025-06-30 09-29-39.png"><br>

[예시]
### 초반
<img src="./img_250630/Screenshot from 2025-06-30 09-32-18.png"><br>

### 후반
<img src="./img_250630/Screenshot from 2025-06-30 09-32-49.png"><br>

- Layer를 거칠수록 이미지의 특징이 강화됨

### 합성곱 계산
<img src="./img_250630/Screenshot from 2025-06-30 09-34-08.png"><br>

### Filter

- 합성곱 연산 과정은 입력 이미지에 특정 사이즈의 텐서를 사용
  - 전체 이미지의 일부를 스캔해가면 연산
- 스캔하는 텐서 == 필터
- 보통 3x3 필터를 많이 사용
- 필터의 두께 == 입력 데이터의 두께
  - 입력이 컬러이미지
  - 두께는 3차원
  - 필터의 두께도 3으로 세팅됨

### Feature map
  
- 입력 데이털를 필터로 스캔한 결과 
  - 이 출력 텐서를 feature map이라 함
- 합성곱 층에서 필터의 수만큼 feature map 생성

### stride
- 필터가 움직이는 간격
- stride가 크면
  - 특징을 제대로 추출어려움
    - 듬성듬성 스캔함
  - 연산 속도는 빨라짐
- stride가 작으면
  - 특징을 세부적으로 추출 가능
  - 연산 속도는 느림
- 보통 (1,1)을 사용
  - 그 이상은 연산 속도보다 성능의 이점이 매우 떨어짐
  - 사용할 이유가 없음

### Padding

<img src="./img_250630/Screenshot from 2025-06-30 09-40-15.png"><br>

- 입력 데이터에 대해 합성곱 연산을 수행하여 만들어진 feature map
  - 원래 입력 데이터보다 사이즈가 작아짐
- 데이터의 크기가 작으면 합성곱 층을 추가하기 어려움
- padding을 덧대어 출력의 크기를 입력의 크기와 맞춰줌

### Activation
- 주로 ReLU 함수를 주로 사용
  - 혹은 ReLU 변형을 사용
- 합성곱 층 개수는 설정에 따라 달라짐
- 각 합성곱층 뒤에 Pooling layer를 붙이기도 함

### Pooling Layer

#### Max Pooling
<img src="./img_250630/Screenshot from 2025-06-30 09-43-07.png"><br>

- 최댓값을 찾음

#### Average Pooling
<img src="./img_250630/Screenshot from 2025-06-30 09-43-49.png"><br>

- 평균값을 산출함

#### GloabalAveragePooling
> 자주 사용되진 않음

<img src="./img_250630/Screenshot from 2025-06-30 09-44-49.png"><br>

- 합성곱 연산으로 나온 하나의 feature map을 평균값을 출력함
- 이전 Pooling 계산보다 크기를 많이 줄임

### Fully Connected Layer
- Convolution-Pooling Layer를 처리된 결과를 Flatten으로 벡터화하여 입력으로 들어감
- 딥러닝 목적에 맞게 출력 크기를 맞춰줌
- 이전까지 처리된 데이터 == Tensor
  - Flatten을 거쳐 벡터로 만들어줘야함
- 출력의 크기 == Class의 종류

## Transfer Learning

<img src="./img_250630/Screenshot from 2025-06-30 09-58-58.png"><br>

- 이미 학습된 모델을 기반으로
  - 출력층만 변경해 새로운 데이터를 학습하는 방식
- 처음부터 학습하는 것보다 데이터 및 시간 절약, 성능 개선 기대 가능

### 전이 학습 방법
- 특성 추출
  - 기존 모델의 가중치를 고정하고 출력층만 새롭게 학습
- 미세 조정
  - 기존 모델의 일부 층까지 고정
    - 일부 층 또는 전부를 재학습
  - 새 데이터 양이 많을수록 미세조정의 범위를 넓힘
  - 데이터 양이 적을 수록 출력층만 조절 가능
  - 적은 데이터로도 좋은 성능 가능


